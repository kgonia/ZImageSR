{"cells":[{"cell_type":"markdown","metadata":{"id":"BIsxgQR1lrbu"},"source":["# Z-Image Turbo + FluxSR FTD — Fixed Colab Training Notebook\n","\n","**Key fixes over previous version:**\n","- `call_transformer` converts `(B,C,H,W)` → `List[(C,1,H,W)]` per sample (Z-Image's expected format)\n","- `all_cap_feats` passed as `List[Tensor(seq_len, cap_dim)]` per sample\n","- Debug cell dumps model shapes/signatures to files for inspection\n","- No duplicate definitions; every cell is safe to re-run\n","- Consistent `call_transformer` signature across FTD and recon loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N--YYJX6lrbx"},"outputs":[],"source":["!pip -q install -U diffusers accelerate peft transformers safetensors torchvision lpips"]},{"cell_type":"markdown","metadata":{"id":"HC7isM6xlrby"},"source":["## 1) Mount Drive + unzip dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1024,"status":"ok","timestamp":1770412253246,"user":{"displayName":"Krzysztof Gonia","userId":"16352453138188834576"},"user_tz":-60},"id":"tWPafQLmlrby","outputId":"24426591-bbe1-44b9-dad5-363bbcd07d72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","PAIRS_DIR: /content/zimage_offline_pairs/pairs\n","Num samples: 1200\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import shutil\n","from pathlib import Path\n","\n","# -------- EDIT THESE --------\n","ZIP_NAME = \"zimage_offline_pairs_with_lr.zip\"\n","DRIVE_ZIP_PATH = f\"/content/drive/MyDrive/{ZIP_NAME}\"\n","WORKDIR = Path(\"/content\")\n","# ---------------------------\n","\n","local_zip = WORKDIR / ZIP_NAME\n","print(\"Copying zip from Drive:\", DRIVE_ZIP_PATH)\n","shutil.copy(DRIVE_ZIP_PATH, local_zip)\n","\n","print(\"Unzipping...\")\n","!unzip -q -o \"{local_zip}\" -d \"{WORKDIR}\"\n","\n","\n","PAIRS_DIR = Path(\"/content/zimage_offline_pairs/pairs\")\n","print(\"PAIRS_DIR:\", PAIRS_DIR)\n","print(\"Num samples:\", len([d for d in PAIRS_DIR.iterdir() if d.is_dir()]))\n"]},{"cell_type":"markdown","metadata":{"id":"Q5xVEC6tlrby"},"source":["## 2) Load Z-Image Turbo pipeline once"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237,"referenced_widgets":["367b8f0b476643c88ec14e27d4cbb7bc","402e82ae845747099a2531c762f9793d","04b3c014948347069505323cf29bb490","046822aa73e04d629bb6c08cb8a3c5a2","d03a15f4ea904f20b30a50de351dfb24","c9c2aaa925834f989653b862d2b34bf8","e567e8cc52b6496e8ed36779c7520ffc","ca04e651c49d44cd9bb6bdd891bf3931","0c6f02f6dd05405dbb337d2bb83b0e88","277b06e59e8d4efda8f4191847604cab","ac9b86aaca184d2bad828291532fd133","5832fca62a454d119483f9beef1a48d5","753e7fbec93344cba14268d1a344d9b8","b7d6492475334a89ab16019078930e05","04bfbfea2e7843268e4e368c26c18f46","8878971d51fe4a14af962a0ad8b23dcb","d871931d730540b28eb00eae798057ba","f8e142d4fbb04bb0912f652b0fd39915","808e29b154da42f5941fe6394b943f6c","4535e2eb4a8a4593ba9479f8f22c1671","ed9030952f174480a2879599615144be","378a6936d72a4a31bfe5d35f2c73551a","903946684afd49b7a25c9d45e403d115","880855abf500493eb045c584d1c0e91c","723a41d3a230445b9b6a5465b8142d4e","028e0fd6c450425d822215bc2414a006","774bb2ba9ea74153a8e50ef9305568f5","39bc4c5bf9154269811a3c36be96413d","e866ed41010f46fa9f7073554ea4dbcb","bfa3bff1628d4d2db11923c138d098ca","33d5187ebde84f4ba9a1210c9f143a29","b2429185bc07459dafa0b6d00927b926","6791d40bbe834474860caae6ceaf81d1"]},"executionInfo":{"elapsed":26538,"status":"ok","timestamp":1770412282753,"user":{"displayName":"Krzysztof Gonia","userId":"16352453138188834576"},"user_tz":-60},"id":"FtO2BjBdlrbz","outputId":"a287dd37-ab19-4759-d978-d0602ddc970e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n","Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"367b8f0b476643c88ec14e27d4cbb7bc","version_major":2,"version_minor":0},"text/plain":["Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5832fca62a454d119483f9beef1a48d5","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"903946684afd49b7a25c9d45e403d115","version_major":2,"version_minor":0},"text/plain":["Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["t_scale=1000.0, vae_sf=0.3611, vae_sh=0.1159\n","WARNING: encode_prompt returned no tensor\n","transformer.forward signature: (x: List[torch.Tensor], t, cap_feats: List[torch.Tensor], patch_size=2, f_patch_size=1, return_dict: bool = True)\n","Pipeline ready.\n"]}],"source":["import torch, numpy as np, inspect, json\n","from diffusers import ZImageImg2ImgPipeline\n","\n","DTYPE = \"bf16\"  # \"bf16\" or \"fp16\"\n","torch_dtype = torch.bfloat16 if DTYPE == \"bf16\" else torch.float16\n","device = \"cuda\"\n","MODEL_ID = \"Tongyi-MAI/Z-Image-Turbo\"\n","\n","pipe = ZImageImg2ImgPipeline.from_pretrained(MODEL_ID, torch_dtype=torch_dtype).to(device)\n","\n","pipe.vae.requires_grad_(False)\n","if getattr(pipe, \"text_encoder\", None) is not None:\n","    pipe.text_encoder.requires_grad_(False)\n","pipe.transformer.requires_grad_(False)\n","\n","torch.backends.cuda.matmul.allow_tf32 = True\n","torch.set_float32_matmul_precision(\"high\")\n","\n","t_scale = float(getattr(pipe.transformer.config, \"t_scale\", 1.0))\n","vae_sf = float(getattr(pipe.vae.config, \"scaling_factor\", 1.0))\n","vae_sh = float(getattr(pipe.vae.config, \"shift_factor\", 0.0))\n","print(f\"t_scale={t_scale}, vae_sf={vae_sf}, vae_sh={vae_sh}\")\n","\n","# --- Null conditioning ---\n","with torch.no_grad():\n","    sig = inspect.signature(pipe.encode_prompt)\n","    kwargs = {}\n","    if \"device\" in sig.parameters: kwargs[\"device\"] = device\n","    if \"do_classifier_free_guidance\" in sig.parameters: kwargs[\"do_classifier_free_guidance\"] = False\n","    if \"num_images_per_prompt\" in sig.parameters: kwargs[\"num_images_per_prompt\"] = 1\n","    pe = pipe.encode_prompt(\"\", **kwargs)\n","\n","# Extract first tensor from encode_prompt result\n","null_cap_feats = None\n","def _first_tensor(x):\n","    if torch.is_tensor(x): return x\n","    if isinstance(x, (tuple, list)):\n","        for v in x:\n","            if torch.is_tensor(v): return v\n","    return None\n","\n","null_cap_feats = _first_tensor(pe)\n","if null_cap_feats is not None:\n","    null_cap_feats = null_cap_feats.detach()\n","    print(\"null_cap_feats:\", tuple(null_cap_feats.shape), null_cap_feats.dtype)\n","else:\n","    print(\"WARNING: encode_prompt returned no tensor\")\n","\n","# Offload text encoder\n","if getattr(pipe, \"text_encoder\", None) is not None:\n","    pipe.text_encoder.to(\"cpu\")\n","    torch.cuda.empty_cache()\n","\n","# Gradient checkpointing\n","if hasattr(pipe.transformer, \"enable_gradient_checkpointing\"):\n","    pipe.transformer.enable_gradient_checkpointing()\n","\n","print(\"transformer.forward signature:\", inspect.signature(pipe.transformer.forward))\n","print(\"Pipeline ready.\")\n"]},{"cell_type":"markdown","metadata":{"id":"30P8f8Xplrbz"},"source":["## 2b) DEBUG: Introspect transformer & dump shapes to files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q9lUJJ6Ulrbz"},"outputs":[],"source":["import inspect, json, traceback\n","\n","DEBUG_DIR = Path(\"/content/debug_shapes\")\n","DEBUG_DIR.mkdir(exist_ok=True)\n","\n","# --- 1. Forward signature ---\n","sig = inspect.signature(pipe.transformer.forward)\n","sig_str = str(sig)\n","print(\"Forward signature:\", sig_str)\n","with open(DEBUG_DIR / \"forward_signature.txt\", \"w\") as f:\n","    f.write(sig_str + \"\\n\")\n","    for name, p in sig.parameters.items():\n","        f.write(f\"  {name}: default={p.default}, kind={p.kind}\\n\")\n","\n","# --- 2. Source of patchify_and_embed (if accessible) ---\n","try:\n","    src = inspect.getsource(pipe.transformer.patchify_and_embed)\n","    with open(DEBUG_DIR / \"patchify_and_embed_source.py\", \"w\") as f:\n","        f.write(src)\n","    print(\"Saved patchify_and_embed source\")\n","except Exception as e:\n","    print(f\"Could not get patchify_and_embed source: {e}\")\n","\n","# --- 3. Source of forward ---\n","try:\n","    # unwrap PEFT if present\n","    base = pipe.transformer\n","    if hasattr(base, \"base_model\"):\n","        base = base.base_model\n","    if hasattr(base, \"model\"):\n","        base = base.model\n","    src = inspect.getsource(type(base).forward)\n","    with open(DEBUG_DIR / \"forward_source.py\", \"w\") as f:\n","        f.write(src)\n","    print(\"Saved forward source (\", len(src), \"chars)\")\n","except Exception as e:\n","    print(f\"Could not get forward source: {e}\")\n","\n","# --- 4. Config ---\n","config_dict = dict(pipe.transformer.config) if hasattr(pipe.transformer.config, '__iter__') else {}\n","print(\"Transformer config:\", json.dumps(config_dict, indent=2, default=str))\n","with open(DEBUG_DIR / \"transformer_config.json\", \"w\") as f:\n","    json.dump(config_dict, f, indent=2, default=str)\n","\n","# --- 5. Named modules (first 40) ---\n","module_names = [name for name, _ in pipe.transformer.named_modules()]\n","with open(DEBUG_DIR / \"named_modules.txt\", \"w\") as f:\n","    for n in module_names:\n","        f.write(n + \"\\n\")\n","print(f\"Total named modules: {len(module_names)}\")\n","print(\"First 30:\", module_names[:30])\n","\n","# --- 6. Test dummy forward to discover shapes ---\n","print(\"\\n--- Testing dummy forward ---\")\n","B, C, H, W = 1, 16, 64, 64  # 512x512 image at 8x compression\n","dummy_latent = torch.randn(C, 1, H, W, device=device, dtype=torch_dtype)\n","cap_dim = int(getattr(pipe.transformer.config, \"cap_feat_dim\", 2560))\n","\n","# Prepare cap_feats: extract 2D tensor (seq_len, cap_dim)\n","if null_cap_feats is not None:\n","    cf = null_cap_feats\n","    while cf.ndim > 2: cf = cf[0]\n","    if cf.shape[-1] != cap_dim:\n","        cf = torch.zeros(1, cap_dim, device=device, dtype=torch_dtype)\n","else:\n","    cf = torch.zeros(1, cap_dim, device=device, dtype=torch_dtype)\n","\n","print(f\"cap_feats_2d shape: {tuple(cf.shape)}\")\n","t_dummy = torch.tensor([0.5 * t_scale], device=device, dtype=torch_dtype)\n","\n","# Try: all_image = [tensor(C,1,H,W)], all_cap_feats = [tensor(seq,dim)]\n","try:\n","    with torch.no_grad():\n","        out = pipe.transformer(\n","            [dummy_latent],        # List of one (C,1,H,W) tensor\n","            t_dummy,               # (1,) timestep\n","            [cf],                  # List of one (seq_len, cap_dim) tensor\n","            return_dict=True,\n","        )\n","    result = out.sample if hasattr(out, \"sample\") else out[0] if isinstance(out, (tuple,list)) else out\n","    if isinstance(result, list):\n","        print(f\"SUCCESS: output is list of {len(result)} tensors, first shape: {tuple(result[0].shape)}\")\n","        info = f\"list of {len(result)}, shapes: {[tuple(r.shape) for r in result]}\"\n","    else:\n","        print(f\"SUCCESS: output tensor shape: {tuple(result.shape)}\")\n","        info = f\"tensor shape: {tuple(result.shape)}\"\n","    with open(DEBUG_DIR / \"dummy_forward_result.txt\", \"w\") as f:\n","        f.write(f\"Input: all_image=[({C},1,{H},{W})], t=({t_dummy.shape}), all_cap_feats=[{tuple(cf.shape)}]\\n\")\n","        f.write(f\"Output: {info}\\n\")\n","except Exception as e:\n","    print(f\"FAILED with List[(C,1,H,W)]: {e}\")\n","    traceback.print_exc()\n","    with open(DEBUG_DIR / \"dummy_forward_error.txt\", \"w\") as f:\n","        f.write(traceback.format_exc())\n","\n","    # Fallback: try 5D tensor (B,C,F,H,W)\n","    try:\n","        dummy_5d = torch.randn(1, C, 1, H, W, device=device, dtype=torch_dtype)\n","        with torch.no_grad():\n","            out = pipe.transformer(\n","                [dummy_5d],\n","                t_dummy,\n","                [cf],\n","                return_dict=True,\n","            )\n","        result = out.sample if hasattr(out, \"sample\") else out\n","        print(f\"FALLBACK 5D SUCCESS: {type(result)}, shape: {tuple(result.shape) if torch.is_tensor(result) else 'list'}\")\n","    except Exception as e2:\n","        print(f\"FALLBACK 5D ALSO FAILED: {e2}\")\n","\n","torch.cuda.empty_cache()\n","print(\"\\nDebug files saved to:\", DEBUG_DIR)\n","print(\"Files:\", sorted([p.name for p in DEBUG_DIR.iterdir()]))\n"]},{"cell_type":"markdown","metadata":{"id":"4_DQpHbUlrb0"},"source":["## 3) (Optional) Ensure zL.pt exists"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mK5lSJIwlrb0"},"outputs":[],"source":["from PIL import Image\n","from tqdm.auto import tqdm\n","\n","@torch.no_grad()\n","def vae_encode_latents(pil_img: Image.Image):\n","    img = np.array(pil_img).astype(np.float32) / 255.0\n","    img = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0)\n","    img = img * 2.0 - 1.0\n","    img = img.to(device=device, dtype=torch_dtype)\n","    latents = pipe.vae.encode(img).latent_dist.sample()\n","    return latents * vae_sf  # match Phase 1 convention (scale only, no shift)\n","\n","created = 0\n","for d in tqdm(sorted([p for p in PAIRS_DIR.iterdir() if p.is_dir()]), desc=\"zL.pt\"):\n","    zl = d / \"zL.pt\"\n","    if zl.exists():\n","        continue\n","    lr_up = d / \"lr_up.png\"\n","    if not lr_up.exists():\n","        continue\n","    zL = vae_encode_latents(Image.open(lr_up).convert(\"RGB\")).cpu()\n","    torch.save(zL, zl)\n","    created += 1\n","\n","print(\"Created zL.pt:\", created)\n","torch.cuda.empty_cache()\n"]},{"cell_type":"markdown","metadata":{"id":"iqFf65_2lrb0"},"source":["## 4) Dataset + call_transformer + vae_decode"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72,"status":"ok","timestamp":1770412282837,"user":{"displayName":"Krzysztof Gonia","userId":"16352453138188834576"},"user_tz":-60},"id":"9rDMqBkzlrb0","outputId":"cffe1724-d020-49c2-bebb-9d8fe6de4583"},"outputs":[{"name":"stdout","output_type":"stream","text":["vae_decode patched with autocast\n","Helpers defined.\n"]}],"source":["from pathlib import Path\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","\n","# ──────────────────────────────────────────────────────────\n","# Dataset\n","# ──────────────────────────────────────────────────────────\n","class FTDPairDataset(Dataset):\n","    def __init__(self, pairs_dir: Path, load_pixels: bool):\n","        self.load_pixels = load_pixels\n","        self.items = []\n","        for d in sorted(pairs_dir.iterdir()):\n","            if not d.is_dir():\n","                continue\n","            if (d/\"eps.pt\").exists() and (d/\"z0.pt\").exists() and (d/\"zL.pt\").exists():\n","                if load_pixels and not (d/\"x0.png\").exists():\n","                    continue\n","                self.items.append(d)\n","        if not self.items:\n","            raise RuntimeError(\"No valid samples found.\")\n","\n","    def __len__(self): return len(self.items)\n","\n","    def __getitem__(self, idx):\n","        d = self.items[idx]\n","        eps = torch.load(d/\"eps.pt\", map_location=\"cpu\").squeeze(0)  # (C, H, W)\n","        z0  = torch.load(d/\"z0.pt\",  map_location=\"cpu\").squeeze(0)\n","        zL  = torch.load(d/\"zL.pt\",  map_location=\"cpu\").squeeze(0)\n","        out = {\"eps\": eps, \"z0\": z0, \"zL\": zL}\n","        if self.load_pixels:\n","            from PIL import Image as _Img\n","            x0 = _Img.open(d/\"x0.png\").convert(\"RGB\")\n","            x0 = np.array(x0).astype(np.float32) / 255.0\n","            x0 = torch.from_numpy(x0).permute(2, 0, 1)\n","            out[\"x0_pixels\"] = x0\n","        return out\n","\n","def ftd_collate(batch):\n","    out = {k: torch.stack([b[k] for b in batch]) for k in batch[0]}\n","    return out\n","\n","# ──────────────────────────────────────────────────────────\n","# call_transformer — Z-Image format conversion\n","# ──────────────────────────────────────────────────────────\n","# Z-Image transformer.forward expects:\n","#   all_image:     List[Tensor(C, F, H, W)] — one 4D tensor per batch sample, F=1\n","#   t:             Tensor — timestep(s)\n","#   all_cap_feats: List[Tensor(seq_len, cap_dim)] — one 2D tensor per batch sample\n","#\n","# We convert from our (B, C, H, W) training tensors to this format.\n","# ──────────────────────────────────────────────────────────\n","\n","def call_transformer(transformer, *, latents, timestep, cap_feats_2d):\n","    \"\"\"\n","    Args:\n","        latents:     (B, C, H, W) float tensor\n","        timestep:    (B,) float tensor (already multiplied by t_scale)\n","        cap_feats_2d: (seq_len, cap_dim) — single 2D tensor, replicated per sample\n","    Returns:\n","        (B, C, H, W) velocity prediction\n","    \"\"\"\n","    B = latents.shape[0]\n","\n","    # Convert (B, C, H, W) -> List of (C, 1, H, W) per sample\n","    all_image = [latents[i].unsqueeze(1) for i in range(B)]  # each: (C, 1, H, W)\n","\n","    # Cap feats: one per sample\n","    all_cap_feats = [cap_feats_2d for _ in range(B)]  # each: (seq_len, cap_dim)\n","\n","    out = transformer(\n","        all_image,\n","        timestep,\n","        all_cap_feats,\n","        return_dict=False,\n","    )\n","\n","    # Unwrap output\n","    if isinstance(out, (tuple, list)):\n","        result = out[0]\n","    else:\n","        result = out\n","\n","    # Output may be list of per-sample tensors or a stacked tensor\n","    if isinstance(result, list):\n","        # Each element: (C, 1, H, W) or (C, H, W)\n","        processed = []\n","        for r in result:\n","            if r.ndim == 4 and r.shape[1] == 1:\n","                r = r.squeeze(1)  # (C, 1, H, W) -> (C, H, W)\n","            processed.append(r)\n","        result = torch.stack(processed, dim=0)  # (B, C, H, W)\n","    elif result.ndim == 5 and result.shape[2] == 1:\n","        result = result.squeeze(2)  # (B, C, 1, H, W) -> (B, C, H, W)\n","\n","    return result\n","\n","\n","def vae_decode(pipe, z):\n","    \"\"\"Decode latents -> pixels [0,1]. Force bf16 via autocast.\"\"\"\n","    z_raw = z / vae_sf\n","    with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n","        x = pipe.vae.decode(z_raw).sample\n","    return (x / 2 + 0.5).clamp(0, 1)\n","\n","print(\"vae_decode patched with autocast\")\n","\n","print(\"Helpers defined.\")\n"]},{"cell_type":"markdown","metadata":{"id":"t-8-oHcWlrb1"},"source":["## 5) TV-LPIPS + ADL losses"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1770412282864,"user":{"displayName":"Krzysztof Gonia","userId":"16352453138188834576"},"user_tz":-60},"id":"uJYu1sqOlrb1","outputId":"5987ade2-5e07-454a-a938-673d723ed861"},"outputs":[{"name":"stdout","output_type":"stream","text":["Losses defined.\n"]}],"source":["import lpips\n","\n","def total_variation_filter(x):\n","    dh = torch.abs(x[:, :, 1:, :-1] - x[:, :, :-1, :-1])\n","    dw = torch.abs(x[:, :, :-1, 1:] - x[:, :, :-1, :-1])\n","    return dh + dw\n","\n","class TVLPIPSLoss(torch.nn.Module):\n","    def __init__(self, gamma=0.5):\n","        super().__init__()\n","        self.gamma = gamma\n","        self.lpips_fn = lpips.LPIPS(net=\"vgg\")\n","        for p in self.lpips_fn.parameters():\n","            p.requires_grad_(False)\n","\n","    def forward(self, x, y):\n","        xn, yn = x * 2 - 1, y * 2 - 1\n","        loss1 = self.lpips_fn(xn, yn).mean()\n","        tvx, tvy = total_variation_filter(x), total_variation_filter(y)\n","        tv_max = max(tvx.detach().max().item(), tvy.detach().max().item(), 1e-6)\n","        tvx = (tvx / tv_max).clamp(0, 1)\n","        tvy = (tvy / tv_max).clamp(0, 1)\n","        loss2 = self.lpips_fn(tvx * 2 - 1, tvy * 2 - 1).mean()\n","        return loss1 + self.gamma * loss2\n","\n","print(\"Losses defined.\")\n"]},{"cell_type":"markdown","metadata":{"id":"I3yMv6rclrb1"},"source":["## 6) FTD Training Loop\n","\n","FluxSR FTD (Eq.16/17/18/21). Key points:\n","- LoRA on transformer attention layers only\n","- `call_transformer` properly converts to Z-Image's List format\n","- FTD loss on randomly sampled t ∈ [TL, 1]\n","- Pixel recon loss every N steps\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1770412282895,"user":{"displayName":"Krzysztof Gonia","userId":"16352453138188834576"},"user_tz":-60},"id":"BSZaWM9htukm","outputId":"e6a248af-ef25-4251-82ef-603646127908"},"outputs":[{"name":"stdout","output_type":"stream","text":["Disabled VAE force_upcast\n"]}],"source":["pipe.vae.config.force_upcast = False\n","print(\"Disabled VAE force_upcast\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":940,"referenced_widgets":["585a46a2514f43a1b8084e9e8710cc5f","ea21b2b1dad2492480d772f1c621052e","9fd35afcfcb04d0ea3cada7f5c805179","9ee1d63703c9432e97eac84be67e8adc","e309922ffab04880a1bb4f36200fc0a8","24f14c413fff4dbf8363ecc30a89f4bd","3421381aa6844b1ebc534b0fd3b6a1b9","c7a17cb16a904b0ba2da296af6a32848","d52637d39cf245c7bd3203ebbed1b9cc","b43776cbcafa40c09f5651f9732a9797","56206a5dc9c04615915e8a2838885df3"]},"executionInfo":{"elapsed":4016600,"status":"error","timestamp":1770416299496,"user":{"displayName":"Krzysztof Gonia","userId":"16352453138188834576"},"user_tz":-60},"id":"n53XgseMlrb1","outputId":"67552353-ffe5-4dd7-eb10-302d5676cf01"},"outputs":[{"name":"stdout","output_type":"stream","text":["[LoRA] Targeting 136 layers. First 15:\n","  context_refiner.0.attention.to_k\n","  context_refiner.0.attention.to_out.0\n","  context_refiner.0.attention.to_q\n","  context_refiner.0.attention.to_v\n","  context_refiner.1.attention.to_k\n","  context_refiner.1.attention.to_out.0\n","  context_refiner.1.attention.to_q\n","  context_refiner.1.attention.to_v\n","  layers.0.attention.to_k\n","  layers.0.attention.to_out.0\n","  layers.0.attention.to_q\n","  layers.0.attention.to_v\n","  layers.1.attention.to_k\n","  layers.1.attention.to_out.0\n","  layers.1.attention.to_q\n","trainable params: 16,711,680 || all params: 6,171,620,416 || trainable%: 0.2708\n","cap_feats_2d: (1, 2560), cap_dim=2560\n","Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["Loading model from: /usr/local/lib/python3.12/dist-packages/lpips/weights/v0.1/vgg.pth\n","FTDPairDataset: 1199 samples\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"585a46a2514f43a1b8084e9e8710cc5f","version_major":2,"version_minor":0},"text/plain":["FluxSR-FTD:   0%|          | 0/3000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","[Step 500] Saved: /content/drive/MyDrive/zimage_sr_lora_runs/ftd_run_v2/lora_step_500 (OK)\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1534850896.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_FTD\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mL_Rec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2850\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             )\n\u001b[0;32m--> 630\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    866\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os, inspect, math\n","from pathlib import Path\n","from accelerate import Accelerator\n","from peft import LoraConfig, get_peft_model\n","from tqdm.auto import tqdm\n","\n","# ── Hyperparams ── for 40GB\n","TL          = 0.25 # 0.15\n","BATCH_SIZE  = 4 # 1\n","GRAD_ACCUM  = 2 # 8\n","LR          = 5e-5 # 1e-4\n","MAX_STEPS   = 750\n","LOG_EVERY   = 20\n","SAVE_EVERY  = 150 #500\n","REC_LOSS_EVERY = 8      # set to 0 to disable, increase if OOM\n","LAMBDA_TVLPIPS = 1.0\n","GAMMA_TV       = 0.5\n","\n","SAVE_DIR = Path(\"/content/drive/MyDrive/zimage_sr_lora_runs/ftd_run_v2\")\n","SAVE_DIR.mkdir(parents=True, exist_ok=True)\n","\n","accelerator = Accelerator(mixed_precision=\"no\", gradient_accumulation_steps=GRAD_ACCUM)\n","device = accelerator.device\n","\n","# ── Safety: prevent double LoRA ──\n","# ── Safety: remove existing LoRA if re-running ──\n","if hasattr(pipe.transformer, \"peft_config\"):\n","    print(\"Reloading clean transformer...\")\n","    from diffusers import ZImageTransformer2DModel\n","    pipe.transformer = ZImageTransformer2DModel.from_pretrained(\n","        MODEL_ID, subfolder=\"transformer\", torch_dtype=torch_dtype\n","    ).to(device)\n","    pipe.transformer.requires_grad_(False)\n","    if hasattr(pipe.transformer, \"enable_gradient_checkpointing\"):\n","        pipe.transformer.enable_gradient_checkpointing()\n","\n","# ── LoRA setup ──\n","pipe.transformer.requires_grad_(False)\n","\n","# Find attention Linear layers (avoid norms, embeds, time projections, PEFT internals)\n","def find_lora_targets(model):\n","    names = []\n","    for name, mod in model.named_modules():\n","        if not isinstance(mod, torch.nn.Linear):\n","            continue\n","        if any(x in name for x in [\"lora_\", \"base_layer\", \"peft_\", \"norm\", \"embed\", \"time\", \"t_embed\", \"pos\"]):\n","            continue\n","        if any(x in name for x in [\"attention\", \"attn\", \"to_q\", \"to_k\", \"to_v\", \"to_out\", \"proj\", \"mlp\", \"ff\"]):\n","            names.append(name)\n","    return sorted(set(names))\n","\n","targets = find_lora_targets(pipe.transformer)\n","if not targets:\n","    # Fallback: all Linear layers except norms/embeds\n","    targets = sorted(set(\n","        name for name, mod in pipe.transformer.named_modules()\n","        if isinstance(mod, torch.nn.Linear) and not any(x in name for x in [\"lora_\", \"base_layer\", \"norm\", \"embed\"])\n","    ))\n","\n","print(f\"[LoRA] Targeting {len(targets)} layers. First 15:\")\n","for t in targets[:15]: print(f\"  {t}\")\n","\n","lora_cfg = LoraConfig(r=16, lora_alpha=16, lora_dropout=0.0, bias=\"none\", target_modules=targets)\n","pipe.transformer = get_peft_model(pipe.transformer, lora_cfg)\n","pipe.transformer.print_trainable_parameters()\n","\n","# ── Conditioning: prepare cap_feats_2d ──\n","cap_dim = int(getattr(pipe.transformer.config, \"cap_feat_dim\", 2560))\n","\n","if null_cap_feats is not None:\n","    cf = null_cap_feats.to(device=device, dtype=torch_dtype)\n","    while cf.ndim > 2: cf = cf[0]         # (B, S, D) -> (S, D)\n","    if cf.ndim == 1: cf = cf.unsqueeze(0)  # (D,) -> (1, D)\n","    if cf.shape[-1] != cap_dim:\n","        print(f\"[WARN] cap_feats dim {cf.shape[-1]} != {cap_dim}, using zeros\")\n","        cf = torch.zeros(1, cap_dim, device=device, dtype=torch_dtype)\n","else:\n","    cf = torch.zeros(1, cap_dim, device=device, dtype=torch_dtype)\n","\n","cap_feats_2d = cf.detach()\n","print(f\"cap_feats_2d: {tuple(cap_feats_2d.shape)}, cap_dim={cap_dim}\")\n","\n","# ── TV-LPIPS ──\n","tv_lpips = TVLPIPSLoss(gamma=GAMMA_TV).eval()\n","for p in tv_lpips.parameters(): p.requires_grad_(False)\n","\n","# ── Dataset ──\n","ds = FTDPairDataset(PAIRS_DIR, load_pixels=(REC_LOSS_EVERY > 0))\n","dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2,\n","                collate_fn=ftd_collate, drop_last=True)\n","print(f\"FTDPairDataset: {len(ds)} samples\")\n","\n","# ── Optimizer ──\n","optimizer = torch.optim.AdamW(\n","    [p for p in pipe.transformer.parameters() if p.requires_grad], lr=LR\n",")\n","\n","# ── Accelerator prepare ──\n","pipe.transformer, optimizer, dl = accelerator.prepare(pipe.transformer, optimizer, dl)\n","\n","# ── TL constants ──\n","TL_bc = torch.tensor([TL], device=device, dtype=torch_dtype).view(1, 1, 1, 1)\n","\n","# ── Training ──\n","global_step = 0\n","pipe.transformer.train()\n","pipe.vae.eval()\n","\n","loss_log = {\"ftd\": 0.0, \"rec\": 0.0, \"total\": 0.0}\n","pbar = tqdm(total=MAX_STEPS, desc=\"FluxSR-FTD\")\n","\n","while global_step < MAX_STEPS:\n","    for batch in dl:\n","        if global_step >= MAX_STEPS:\n","            break\n","\n","        eps = batch[\"eps\"].to(device=device, dtype=torch_dtype)\n","        z0  = batch[\"z0\"].to(device=device, dtype=torch_dtype)\n","        zL  = batch[\"zL\"].to(device=device, dtype=torch_dtype)\n","        B = eps.shape[0]\n","\n","        u_t = eps - z0  # Algorithm 1 line 6\n","\n","        with accelerator.accumulate(pipe.transformer):\n","\n","            # ── FTD Loss (Eq. 16/17) ──\n","            t = torch.rand(B, device=device, dtype=torch_dtype) * (1.0 - TL) + TL\n","            t_bc = t.view(B, 1, 1, 1)\n","\n","            # Eq. 16: interpolation\n","            x_t = ((1.0 - t_bc) / (1.0 - TL)) * zL + ((t_bc - TL) / (1.0 - TL)) * eps\n","\n","            v_theta = call_transformer(\n","                pipe.transformer,\n","                latents=x_t,\n","                timestep=t * t_scale,\n","                cap_feats_2d=cap_feats_2d,\n","            )\n","\n","            # Eq. 17\n","            ftd_pred   = u_t - v_theta * TL_bc\n","            ftd_target = eps - zL\n","            L_FTD = F.mse_loss(ftd_pred, ftd_target)\n","\n","            # ── Recon Loss (Eq. 18/21) ──\n","            L_Rec = torch.tensor(0.0, device=device)\n","            do_rec = (REC_LOSS_EVERY > 0) and (global_step % REC_LOSS_EVERY == 0) and (\"x0_pixels\" in batch)\n","\n","            DETACH_LPIPS = True  # Set False to backprop through LPIPS (uses ~40% more VRAM)\n","            DETACH_RECON = True  # True = gradient-free recon (stable), False = full gradients (may OOM/dtype issues)\n","\n","            if do_rec:\n","                x_HR = batch[\"x0_pixels\"].to(device=device, dtype=torch_dtype)\n","                TL_t = torch.full((B,), TL * t_scale, device=device, dtype=torch_dtype)\n","\n","                if DETACH_RECON:\n","                    with torch.no_grad():\n","                        v_TL = call_transformer(\n","                            pipe.transformer, latents=zL, timestep=TL_t, cap_feats_2d=cap_feats_2d,\n","                        )\n","                        z0_hat = zL - v_TL * TL_bc\n","                        x0_hat = vae_decode(pipe, z0_hat)\n","\n","                        L_MSE = F.mse_loss(x0_hat, x_HR)\n","\n","                        tv_lpips.to(device)\n","                        L_TVLP = tv_lpips(x0_hat.float(), x_HR.float())\n","                        tv_lpips.to(\"cpu\")\n","\n","                    L_Rec = (L_MSE + LAMBDA_TVLPIPS * L_TVLP).to(device=device, dtype=torch_dtype)\n","                else:\n","                    v_TL = call_transformer(\n","                        pipe.transformer, latents=zL, timestep=TL_t, cap_feats_2d=cap_feats_2d,\n","                    )\n","                    z0_hat = zL - v_TL * TL_bc\n","                    x0_hat = vae_decode(pipe, z0_hat)\n","\n","                    L_MSE = F.mse_loss(x0_hat, x_HR)\n","\n","                    tv_lpips.to(device)\n","                    L_TVLP = tv_lpips(x0_hat, x_HR)\n","                    tv_lpips.to(\"cpu\")\n","                    torch.cuda.empty_cache()\n","\n","                    L_Rec = L_MSE + LAMBDA_TVLPIPS * L_TVLP\n","\n","            loss = L_FTD + L_Rec\n","\n","            accelerator.backward(loss)\n","            optimizer.step()\n","            optimizer.zero_grad(set_to_none=True)\n","\n","        # ── Logging ──\n","        global_step += 1\n","        loss_log[\"ftd\"]   += L_FTD.item()\n","        loss_log[\"rec\"]   += L_Rec.item()\n","        loss_log[\"total\"] += loss.item()\n","\n","        pbar.update(1)\n","        if global_step % LOG_EVERY == 0:\n","            n = LOG_EVERY\n","            pbar.set_postfix({\n","                \"ftd\": f\"{loss_log['ftd']/n:.4f}\",\n","                \"rec\": f\"{loss_log['rec']/n:.4f}\",\n","                \"tot\": f\"{loss_log['total']/n:.4f}\",\n","            })\n","            loss_log = {k: 0.0 for k in loss_log}\n","\n","        if global_step % SAVE_EVERY == 0:\n","            sp = SAVE_DIR / f\"lora_step_{global_step}\"\n","            sp.mkdir(parents=True, exist_ok=True)\n","            accelerator.unwrap_model(pipe.transformer).save_pretrained(sp)\n","            ok = (sp / \"adapter_config.json\").exists()\n","            print(f\"\\n[Step {global_step}] Saved: {sp} ({'OK' if ok else 'MISSING adapter_config!'})\")\n","\n","            # --- quick inference ---\n","            try:\n","                pipe.transformer.eval()\n","                with torch.no_grad():\n","                    sample = ds[0]  # first pair\n","                    zL_s = sample[\"zL\"].unsqueeze(0).to(device=device, dtype=torch_dtype)\n","                    TL_t = torch.tensor([TL], device=device, dtype=torch_dtype)\n","                    TL_bc = TL_t.view(1,1,1,1)\n","\n","                    v = call_transformer(pipe.transformer, latents=zL_s, timestep=TL_t, cap_feats_2d=null_cap_feats)\n","                    z0_hat = zL_s - v * TL_bc\n","                    img = vae_decode(pipe, z0_hat)[0]  # (C,H,W)\n","                    img_pil = TF.to_pil_image(img.clamp(0,1).float().cpu())\n","\n","                    out_path = SAVE_DIR / f\"sr_step_{global_step}.png\"\n","                    img_pil.save(out_path)\n","                    print(f\"[Step {global_step}] Inference saved: {out_path}\")\n","\n","                    # display inline if notebook\n","                    try:\n","                        from IPython.display import display\n","                        display(img_pil.resize((512,512), Image.LANCZOS))\n","                    except: pass\n","                pipe.transformer.train()\n","            except Exception as e:\n","                print(f\"[Step {global_step}] Inference failed: {e}\")\n","                pipe.transformer.train()\n","\n","pbar.close()\n","\n","# Final save\n","final = SAVE_DIR / \"lora_final\"\n","final.mkdir(parents=True, exist_ok=True)\n","accelerator.unwrap_model(pipe.transformer).save_pretrained(final)\n","print(\"Final LoRA saved:\", final)\n","print(\"Files:\", sorted([p.name for p in final.iterdir()]))\n"]},{"cell_type":"markdown","metadata":{"id":"KyQvpe66lrb1"},"source":["## 7) One-step inference sanity check"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Ug4PaC4Uf90JwQyBSi0c-gOAlzZAF0dN"},"executionInfo":{"elapsed":16899,"status":"ok","timestamp":1770416558205,"user":{"displayName":"Krzysztof Gonia","userId":"16352453138188834576"},"user_tz":-60},"id":"O7bwrtEolrb2","outputId":"e11389c3-1742-4ab3-b8ae-89a49048557d"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import random\n","from PIL import Image, ImageDraw\n","from peft import PeftModel\n","import torchvision.transforms.functional as TF\n","\n","# Re-encode null conditioning if needed\n","if null_cap_feats is None or not isinstance(null_cap_feats, torch.Tensor):\n","    cap_dim = getattr(pipe.transformer, 'config', None)\n","    if cap_dim and hasattr(cap_dim, 'cap_feat_dim'):\n","        cap_dim = cap_dim.cap_feat_dim\n","    else:\n","        cap_dim = 2560\n","    null_cap_feats = torch.zeros(1, cap_dim, device=device, dtype=torch_dtype)\n","    print(f\"null_cap_feats: {null_cap_feats.shape}\")\n","\n","# Pick random sample\n","d = random.choice([p for p in PAIRS_DIR.iterdir() if p.is_dir()])\n","print(\"Sample:\", d.name)\n","\n","zL = torch.load(d/\"zL.pt\", map_location=\"cpu\").to(device=device, dtype=torch_dtype)\n","if zL.ndim == 3: zL = zL.unsqueeze(0)\n","\n","TL_t  = torch.tensor([TL], device=device, dtype=torch_dtype)\n","TL_bc = TL_t.view(1,1,1,1)\n","\n","# --- Unwrap to clean base transformer ---\n","base_tr = accelerator.unwrap_model(pipe.transformer)\n","if hasattr(base_tr, 'base_model'):  # it's a PeftModel from training\n","    base_tr = base_tr.base_model.model  # raw ZImageTransformer2DModel\n","    print(\"Unwrapped PeftModel to base transformer\")\n","\n","# --- Base model SR (no LoRA) ---\n","base_tr.eval()\n","with torch.no_grad():\n","    v_base = call_transformer(base_tr, latents=zL, timestep=TL_t, cap_feats_2d=null_cap_feats)\n","    z0_base = zL - v_base * TL_bc\n","    base_img = vae_decode(pipe, z0_base)[0]\n","    lr_dec   = vae_decode(pipe, zL)[0]\n","\n","# --- Load LoRA on clean base and run SR ---\n","lora_path = str(SAVE_DIR / \"lora_step_500\")  # or lora_final\n","lora_tr = PeftModel.from_pretrained(base_tr, lora_path).to(device)\n","lora_tr.eval()\n","print(\"LoRA loaded cleanly\")\n","\n","with torch.no_grad():\n","    v_lora = call_transformer(lora_tr, latents=zL, timestep=TL_t, cap_feats_2d=null_cap_feats)\n","    z0_lora = zL - v_lora * TL_bc\n","    lora_img = vae_decode(pipe, z0_lora)[0]\n","\n","# --- Restore pipe.transformer to LoRA version for further use ---\n","pipe.transformer = lora_tr\n","\n","def to_pil(t): return TF.to_pil_image(t.clamp(0,1).float().cpu())\n","\n","hr_pil = Image.open(d/\"x0.png\").convert(\"RGB\")\n","\n","# Side-by-side: LR | Base SR | LoRA SR | HR\n","imgs   = [to_pil(lr_dec), to_pil(base_img), to_pil(lora_img), hr_pil]\n","labels = [\"LR (decoded)\", \"Base model SR\", \"LoRA SR\", \"HR ground truth\"]\n","\n","W, H = imgs[0].size\n","canvas = Image.new(\"RGB\", (W*4, H+24), \"white\")\n","draw = ImageDraw.Draw(canvas)\n","for i, (img, lbl) in enumerate(zip(imgs, labels)):\n","    canvas.paste(img.resize((W, H)), (W*i, 0))\n","    draw.text((W*i + 4, H+4), lbl, fill=\"black\")\n","\n","canvas.save(SAVE_DIR / \"eval_base_vs_lora.png\")\n","display(canvas)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66,"status":"ok","timestamp":1770416899732,"user":{"displayName":"Krzysztof Gonia","userId":"16352453138188834576"},"user_tz":-60},"id":"3pf-jO15EGd7","outputId":"c75f0ca8-5c82-4f23-d5cb-a1b6eaab22eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["v_base vs v_lora mean abs diff: 0.0\n"]}],"source":["# Add this right after both inferences:\n","diff = (v_lora - v_base).abs().mean().item()\n","print(f\"v_base vs v_lora mean abs diff: {diff}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74,"status":"ok","timestamp":1770416903860,"user":{"displayName":"Krzysztof Gonia","userId":"16352453138188834576"},"user_tz":-60},"id":"4JTCH1sIEKXH","outputId":"c1cc27a9-75c9-4788-f737-45fac22eebb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["First 5 keys: ['base_model.model.context_refiner.0.attention.to_k.lora_A.weight', 'base_model.model.context_refiner.0.attention.to_k.lora_B.weight', 'base_model.model.context_refiner.0.attention.to_out.0.lora_A.weight', 'base_model.model.context_refiner.0.attention.to_out.0.lora_B.weight', 'base_model.model.context_refiner.0.attention.to_q.lora_A.weight']\n","Total keys: 272\n"]}],"source":["import safetensors\n","from pathlib import Path\n","\n","lora_path = str(SAVE_DIR / \"lora_step_500_fixed\")\n","# Check saved key names\n","st_file = list(Path(lora_path).glob(\"*.safetensors\"))[0]\n","keys = list(safetensors.safe_open(str(st_file), framework=\"pt\").keys())\n","print(\"First 5 keys:\", keys[:5])\n","print(\"Total keys:\", len(keys))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6iSJuEXEc7T"},"outputs":[],"source":["from safetensors.torch import load_file\n","\n","state = load_file(str(st_file))\n","# Strip double nesting\n","fixed = {}\n","for k, v in state.items():\n","    k_fixed = k.replace(\"base_model.model.base_model.model.\", \"base_model.model.\")\n","    fixed[k_fixed] = v\n","\n","# Save fixed weights\n","from safetensors.torch import save_file\n","fixed_path = SAVE_DIR / \"lora_step_500_fixed\"\n","fixed_path.mkdir(exist_ok=True)\n","save_file(fixed, str(fixed_path / st_file.name))\n","# Copy adapter config\n","import shutil\n","shutil.copy(Path(lora_path)/\"adapter_config.json\", fixed_path/\"adapter_config.json\")\n","\n","# Now load fixed LoRA\n","lora_tr = PeftModel.from_pretrained(base_tr, str(fixed_path)).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":721},"executionInfo":{"elapsed":518,"status":"error","timestamp":1770417012130,"user":{"displayName":"Krzysztof Gonia","userId":"16352453138188834576"},"user_tz":-60},"id":"7M3yh7MwE7TD","outputId":"f51406f8-6270-44bf-ced7-777a8843f604"},"outputs":[{"name":"stdout","output_type":"stream","text":["base_model.model.base_model.model.noise_refiner.0.attention.to_q.lora_A.default.weight: mean=0.008084\n","base_model.model.base_model.model.noise_refiner.0.attention.to_q.lora_B.default.weight: mean=0.000000\n","Active adapter: default\n"]},{"ename":"AttributeError","evalue":"'ZImageTransformer2DModel' object has no attribute 'disabled'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1964\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1966\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'PeftModel' object has no attribute 'disabled'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1964\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1966\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'LoraModel' object has no attribute 'disabled'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1964\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1966\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'PeftModel' object has no attribute 'disabled'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1964\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1966\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'LoraModel' object has no attribute 'disabled'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2391562842.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Check active adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Active adapter:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlora_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adapter enabled:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlora_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"base_model\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# see #1892: prevent infinite recursion if class is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# see #1892: prevent infinite recursion if class is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"base_model\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# see #1892: prevent infinite recursion if class is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# see #1892: prevent infinite recursion if class is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/models/modeling_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# call PyTorch's https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1966\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'ZImageTransformer2DModel' object has no attribute 'disabled'"]}],"source":["# Check if LoRA weights are actually non-zero after loading\n","lora_tr = PeftModel.from_pretrained(base_tr, str(SAVE_DIR / \"lora_step_500\")).to(device)\n","\n","for name, param in lora_tr.named_parameters():\n","    if 'lora_A' in name:\n","        print(f\"{name}: mean={param.abs().mean().item():.6f}\")\n","        break\n","\n","for name, param in lora_tr.named_parameters():\n","    if 'lora_B' in name:\n","        print(f\"{name}: mean={param.abs().mean().item():.6f}\")\n","        break\n","\n","# Check active adapter\n","print(\"Active adapter:\", lora_tr.active_adapter)\n","print(\"Adapter enabled:\", not lora_tr.disabled)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1_MOHHmEuJhD7qpCghludjsttgaQM8F4f","referenced_widgets":["2d1daa276e7c4ffeab9126f3189999d5","18c8313d49ea45aaaa066af84dd6cb84","5c4b5119c90a46619d6eab307e86672f","cef15156bb9941c397a645cfde47b003","d35144db20a64bc99be44bdbda676928","9b83966e037d4ae2ad5aee546e1647cc","14db5140d98a471699c5e54b5ebbf417","136bf2ef18f34392ac00d281885a6c31","7691eea5acb64ab1a18d52363eeb5014","648ba34c24a84a1b9f91be6448971824","0f0b5126a92943aaaf2731aeb51114c3","c14a4b70eb854a38ba9eb7a1a05dd9ca","9b9af38288514b4da376fcc29301f415","574779dc772d4237860af2e68083a4b1","1ccbf3bc21f64ff48da8f2caca19cec2","e9968d88b2824a12b71afbda4ee72c7c","a7099744408a4facacee12597632f1bf","cfde084639e44898971dc5c75418ded6","9b2c7f48c41a4445958507b194f8108c","77cfeb2957f0472190457b94d201417d","f61b1f37c02a4d82a62d9a8d63aa9e56","b97c4215c6e84cb69bcfef235008d1f5","ee68a451858545db919f8871c4979275","d79b1a48a8fc4820be0759cb9c339446","45cfeb2c23924d00a8e67912f675014f","9b770e603e3d47b28916edc63ca07399","89ecb0e3c4414cf98a3a5b1edf1d432b","4862f341caad4d1081ec189844be9719","52628cf128b744e28d6dfd2774f489c5","1ef0f3d94b6349b6a7eb6b85f7f93e96","a3d0235a6b46485aa4c84240463747db","feebbd458cff433791ec9a3e40759766","aa70ebb28905459ab0798a12d3126a6e"]},"executionInfo":{"elapsed":20564,"status":"ok","timestamp":1770417717495,"user":{"displayName":"Krzysztof Gonia","userId":"16352453138188834576"},"user_tz":-60},"id":"k6hVaeObFKYS","outputId":"88ec9fd2-49f5-4d9a-99d9-14c2a05c3bb5"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import random\n","from PIL import Image, ImageDraw\n","from peft import PeftModel\n","import torchvision.transforms.functional as TF\n","from diffusers import ZImageTransformer2DModel\n","\n","# Re-encode null conditioning if needed\n","if null_cap_feats is None or not isinstance(null_cap_feats, torch.Tensor):\n","    null_cap_feats = torch.zeros(1, 2560, device=device, dtype=torch_dtype)\n","\n","# Pick random sample\n","d = random.choice([p for p in PAIRS_DIR.iterdir() if p.is_dir()])\n","print(\"Sample:\", d.name)\n","\n","zL = torch.load(d/\"zL.pt\", map_location=\"cpu\").to(device=device, dtype=torch_dtype)\n","if zL.ndim == 3: zL = zL.unsqueeze(0)\n","\n","TL_t  = torch.tensor([TL], device=device, dtype=torch_dtype)\n","TL_bc = TL_t.view(1,1,1,1)\n","\n","# --- Load FRESH base transformer (no PEFT wrapping) ---\n","base_tr = ZImageTransformer2DModel.from_pretrained(\n","    MODEL_ID, subfolder=\"transformer\", torch_dtype=torch_dtype\n",").to(device)\n","base_tr.eval()\n","\n","# --- Base model SR ---\n","with torch.no_grad():\n","    v_base = call_transformer(base_tr, latents=zL, timestep=TL_t, cap_feats_2d=null_cap_feats)\n","    z0_base = zL - v_base * TL_bc\n","    base_img = vae_decode(pipe, z0_base)[0]\n","    lr_dec   = vae_decode(pipe, zL)[0]\n","\n","# --- Load LoRA on clean base ---\n","lora_path = str(SAVE_DIR / \"lora_step_500\")\n","lora_tr = PeftModel.from_pretrained(base_tr, lora_path).to(device)\n","lora_tr.eval()\n","\n","# Verify weights actually loaded\n","for name, param in lora_tr.named_parameters():\n","    if 'lora_B' in name:\n","        print(f\"{name}: mean={param.abs().mean().item():.6f}\")\n","        break\n","\n","with torch.no_grad():\n","    v_lora = call_transformer(lora_tr, latents=zL, timestep=TL_t, cap_feats_2d=null_cap_feats)\n","    z0_lora = zL - v_lora * TL_bc\n","    lora_img = vae_decode(pipe, z0_lora)[0]\n","\n","diff = (v_lora - v_base).abs().mean().item()\n","print(f\"v_base vs v_lora mean abs diff: {diff}\")\n","\n","# --- Cleanup: free base_tr, keep lora_tr ---\n","del base_tr\n","pipe.transformer = lora_tr\n","\n","def to_pil(t): return TF.to_pil_image(t.clamp(0,1).float().cpu())\n","\n","hr_pil = Image.open(d/\"x0.png\").convert(\"RGB\")\n","\n","imgs   = [to_pil(lr_dec), to_pil(base_img), to_pil(lora_img), hr_pil]\n","labels = [\"LR (decoded)\", \"Base model SR\", \"LoRA SR\", \"HR ground truth\"]\n","\n","W, H = imgs[0].size\n","canvas = Image.new(\"RGB\", (W*4, H+24), \"white\")\n","draw = ImageDraw.Draw(canvas)\n","for i, (img, lbl) in enumerate(zip(imgs, labels)):\n","    canvas.paste(img.resize((W, H)), (W*i, 0))\n","    draw.text((W*i + 4, H+4), lbl, fill=\"black\")\n","\n","canvas.save(SAVE_DIR / \"eval_base_vs_lora.png\")\n","display(canvas)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNWcRm7uF9v3"},"outputs":[],"source":["# Free old transformer\n","try:\n","    if hasattr(pipe, 'transformer') and pipe.transformer is not None:\n","        if hasattr(pipe.transformer, 'to'):\n","            pipe.transformer.to(\"cpu\")\n","        del pipe.transformer\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","except:\n","    gc.collect()\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LrTXvMRpH9v8"},"outputs":[],"source":["import gc\n","pipe.transformer = None\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":346,"output_embedded_package_id":"1fJdMMtRpdOtCGgukWnJ3tncTTPW57xOV","referenced_widgets":["8459e14d7863446ea785833668d70d74","815aa4eff01e4ca79f71b1d4ec8f118c","4315a87fc4fe43ee8e8b82aee857a32e","99d25fb07d054a4aa2957ad542814a24","215ec97ecaed4f5997321ac0d60c942e","358147bc1d4649d483b1b79def664a91","8e6058898f6d44a287160985656fc1ea","9512bc53ca5c40b1b046ca199b79be04","a8e2a328c45f496c926d3ee58f3ef1fb","8094f165d19748dd991f3a65d0524ad9","af63e6c73a194cfdbe1242e0ac8d98c7","1dec465c40f2456d95ab7816f9315e28","1e95f5f58c25453e8abfc43f5ee28eb0","80184e18ffba49e1b0d346075f8847db","4fe1e94a272446e28122021b4cd1ca7b","69754d6650c1403fb21b593af052ac65","59b90526fcef46c38f8671e74bd0b763","c80dac039a3b4bd684e5e25410b6d7e3","35ec0363485c45138cd5ad2b2b01577e","6bc990fc9b234c27bfb110a3d751b1b0","5f75bdadc01249288e5ebaba35164918","8979b08fdcf1475da563ad5db054b30f","d0e76ec973ca48228e2b68d2d60a8dfb","01aa714afc164571831c174680e38093","7fcd83628d564dc1a53d7a00eb3704be","370bb61be8904c7a83acd65bea07e6a7","6eb0aaedf965468b8e70a953517349bc","0a96b4a6fb364b0d9461e827f2855891","3c68466e7a314e72b245821b7dee6ef7","b39a6aca1e1d48128ed9404171acec81","b44d7faecde94666b88a456d94e37222","43989fadb37d4336b9ba1442c2ce1467","23f4d900e7c847dd9e90e9a8bc8e7d70"]},"executionInfo":{"elapsed":34734,"status":"ok","timestamp":1770417845531,"user":{"displayName":"Krzysztof Gonia","userId":"16352453138188834576"},"user_tz":-60},"id":"8CBXIsg3Hyv0","outputId":"140036f2-1783-4e85-bc1d-fd476564788c"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import random, gc\n","from PIL import Image, ImageDraw\n","from peft import PeftModel\n","import torchvision.transforms.functional as TF\n","from diffusers import ZImageTransformer2DModel\n","\n","# Re-encode null conditioning if needed\n","if null_cap_feats is None or not isinstance(null_cap_feats, torch.Tensor):\n","    null_cap_feats = torch.zeros(1, 2560, device=device, dtype=torch_dtype)\n","\n","# Pick random sample\n","d = random.choice([p for p in PAIRS_DIR.iterdir() if p.is_dir()])\n","print(\"Sample:\", d.name)\n","\n","zL = torch.load(d/\"zL.pt\", map_location=\"cpu\").to(device=device, dtype=torch_dtype)\n","if zL.ndim == 3: zL = zL.unsqueeze(0)\n","\n","# Free old transformer\n","if hasattr(pipe, 'transformer') and pipe.transformer is not None:\n","    pipe.transformer.to(\"cpu\")\n","    del pipe.transformer\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","# --- Load FRESH base transformer ---\n","base_tr = ZImageTransformer2DModel.from_pretrained(\n","    MODEL_ID, subfolder=\"transformer\", torch_dtype=torch_dtype\n",").to(device)\n","base_tr.eval()\n","\n","# --- Load LoRA on clean base ---\n","lora_path = str(SAVE_DIR / \"lora_step_500\")\n","lora_tr = PeftModel.from_pretrained(base_tr, lora_path).to(device)\n","lora_tr.eval()\n","\n","for name, param in lora_tr.named_parameters():\n","    if 'lora_B' in name:\n","        print(f\"{name}: mean={param.abs().mean().item():.6f}\")\n","        break\n","\n","def to_pil(t): return TF.to_pil_image(t.clamp(0,1).float().cpu())\n","\n","# --- Decode LR and HR once ---\n","with torch.no_grad():\n","    lr_dec = vae_decode(pipe, zL)[0]\n","hr_pil = Image.open(d/\"x0.png\").convert(\"RGB\")\n","\n","# --- Test multiple TL values ---\n","test_TLs = [0.15, 0.25, 0.35, 0.50]\n","lora_imgs = []\n","\n","for tl in test_TLs:\n","    TL_t  = torch.tensor([tl], device=device, dtype=torch_dtype)\n","    TL_bc = TL_t.view(1,1,1,1)\n","    with torch.no_grad():\n","        v = call_transformer(lora_tr, latents=zL, timestep=TL_t, cap_feats_2d=null_cap_feats)\n","        z0_hat = zL - v * TL_bc\n","        img = vae_decode(pipe, z0_hat)[0]\n","        lora_imgs.append(to_pil(img))\n","    print(f\"TL={tl} done\")\n","\n","# --- Build canvas: LR | TL=0.15 | TL=0.25 | TL=0.35 | TL=0.50 | HR ---\n","all_imgs  = [to_pil(lr_dec)] + lora_imgs + [hr_pil]\n","all_labels = [\"LR\"] + [f\"TL={tl}\" for tl in test_TLs] + [\"HR GT\"]\n","\n","W, H = all_imgs[0].size\n","n = len(all_imgs)\n","canvas = Image.new(\"RGB\", (W*n, H+24), \"white\")\n","draw = ImageDraw.Draw(canvas)\n","for i, (img, lbl) in enumerate(zip(all_imgs, all_labels)):\n","    canvas.paste(img.resize((W, H)), (W*i, 0))\n","    draw.text((W*i + 4, H+4), lbl, fill=\"black\")\n","\n","canvas.save(SAVE_DIR / \"eval_TL_sweep.png\")\n","display(canvas)\n","\n","# Keep lora_tr\n","del base_tr\n","pipe.transformer = lora_tr"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01aa714afc164571831c174680e38093":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a96b4a6fb364b0d9461e827f2855891","placeholder":"​","style":"IPY_MODEL_3c68466e7a314e72b245821b7dee6ef7","value":"Loading checkpoint shards: 100%"}},"028e0fd6c450425d822215bc2414a006":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2429185bc07459dafa0b6d00927b926","placeholder":"​","style":"IPY_MODEL_6791d40bbe834474860caae6ceaf81d1","value":" 398/398 [00:00&lt;00:00, 1174.25it/s, Materializing param=norm.weight]"}},"046822aa73e04d629bb6c08cb8a3c5a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_277b06e59e8d4efda8f4191847604cab","placeholder":"​","style":"IPY_MODEL_ac9b86aaca184d2bad828291532fd133","value":" 5/5 [00:04&lt;00:00,  1.30it/s]"}},"04b3c014948347069505323cf29bb490":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca04e651c49d44cd9bb6bdd891bf3931","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c6f02f6dd05405dbb337d2bb83b0e88","value":5}},"04bfbfea2e7843268e4e368c26c18f46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed9030952f174480a2879599615144be","placeholder":"​","style":"IPY_MODEL_378a6936d72a4a31bfe5d35f2c73551a","value":" 3/3 [00:02&lt;00:00,  1.36it/s]"}},"0a96b4a6fb364b0d9461e827f2855891":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c6f02f6dd05405dbb337d2bb83b0e88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f0b5126a92943aaaf2731aeb51114c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"136bf2ef18f34392ac00d281885a6c31":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"14db5140d98a471699c5e54b5ebbf417":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18c8313d49ea45aaaa066af84dd6cb84":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b83966e037d4ae2ad5aee546e1647cc","placeholder":"​","style":"IPY_MODEL_14db5140d98a471699c5e54b5ebbf417","value":"Download complete: "}},"1ccbf3bc21f64ff48da8f2caca19cec2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f61b1f37c02a4d82a62d9a8d63aa9e56","placeholder":"​","style":"IPY_MODEL_b97c4215c6e84cb69bcfef235008d1f5","value":" 3/3 [00:00&lt;00:00, 281.60it/s]"}},"1dec465c40f2456d95ab7816f9315e28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e95f5f58c25453e8abfc43f5ee28eb0","IPY_MODEL_80184e18ffba49e1b0d346075f8847db","IPY_MODEL_4fe1e94a272446e28122021b4cd1ca7b"],"layout":"IPY_MODEL_69754d6650c1403fb21b593af052ac65"}},"1e95f5f58c25453e8abfc43f5ee28eb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59b90526fcef46c38f8671e74bd0b763","placeholder":"​","style":"IPY_MODEL_c80dac039a3b4bd684e5e25410b6d7e3","value":"Fetching 3 files: 100%"}},"1ef0f3d94b6349b6a7eb6b85f7f93e96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"215ec97ecaed4f5997321ac0d60c942e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23f4d900e7c847dd9e90e9a8bc8e7d70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24f14c413fff4dbf8363ecc30a89f4bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"277b06e59e8d4efda8f4191847604cab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d1daa276e7c4ffeab9126f3189999d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18c8313d49ea45aaaa066af84dd6cb84","IPY_MODEL_5c4b5119c90a46619d6eab307e86672f","IPY_MODEL_cef15156bb9941c397a645cfde47b003"],"layout":"IPY_MODEL_d35144db20a64bc99be44bdbda676928"}},"33d5187ebde84f4ba9a1210c9f143a29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3421381aa6844b1ebc534b0fd3b6a1b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"358147bc1d4649d483b1b79def664a91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35ec0363485c45138cd5ad2b2b01577e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"367b8f0b476643c88ec14e27d4cbb7bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_402e82ae845747099a2531c762f9793d","IPY_MODEL_04b3c014948347069505323cf29bb490","IPY_MODEL_046822aa73e04d629bb6c08cb8a3c5a2"],"layout":"IPY_MODEL_d03a15f4ea904f20b30a50de351dfb24"}},"370bb61be8904c7a83acd65bea07e6a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43989fadb37d4336b9ba1442c2ce1467","placeholder":"​","style":"IPY_MODEL_23f4d900e7c847dd9e90e9a8bc8e7d70","value":" 3/3 [00:02&lt;00:00,  1.54it/s]"}},"378a6936d72a4a31bfe5d35f2c73551a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39bc4c5bf9154269811a3c36be96413d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c68466e7a314e72b245821b7dee6ef7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"402e82ae845747099a2531c762f9793d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9c2aaa925834f989653b862d2b34bf8","placeholder":"​","style":"IPY_MODEL_e567e8cc52b6496e8ed36779c7520ffc","value":"Loading pipeline components...: 100%"}},"4315a87fc4fe43ee8e8b82aee857a32e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9512bc53ca5c40b1b046ca199b79be04","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8e2a328c45f496c926d3ee58f3ef1fb","value":0}},"43989fadb37d4336b9ba1442c2ce1467":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4535e2eb4a8a4593ba9479f8f22c1671":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45cfeb2c23924d00a8e67912f675014f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ef0f3d94b6349b6a7eb6b85f7f93e96","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3d0235a6b46485aa4c84240463747db","value":3}},"4862f341caad4d1081ec189844be9719":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fe1e94a272446e28122021b4cd1ca7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f75bdadc01249288e5ebaba35164918","placeholder":"​","style":"IPY_MODEL_8979b08fdcf1475da563ad5db054b30f","value":" 3/3 [00:00&lt;00:00, 300.72it/s]"}},"52628cf128b744e28d6dfd2774f489c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56206a5dc9c04615915e8a2838885df3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"574779dc772d4237860af2e68083a4b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b2c7f48c41a4445958507b194f8108c","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_77cfeb2957f0472190457b94d201417d","value":3}},"5832fca62a454d119483f9beef1a48d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_753e7fbec93344cba14268d1a344d9b8","IPY_MODEL_b7d6492475334a89ab16019078930e05","IPY_MODEL_04bfbfea2e7843268e4e368c26c18f46"],"layout":"IPY_MODEL_8878971d51fe4a14af962a0ad8b23dcb"}},"585a46a2514f43a1b8084e9e8710cc5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea21b2b1dad2492480d772f1c621052e","IPY_MODEL_9fd35afcfcb04d0ea3cada7f5c805179","IPY_MODEL_9ee1d63703c9432e97eac84be67e8adc"],"layout":"IPY_MODEL_e309922ffab04880a1bb4f36200fc0a8"}},"59b90526fcef46c38f8671e74bd0b763":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c4b5119c90a46619d6eab307e86672f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_136bf2ef18f34392ac00d281885a6c31","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7691eea5acb64ab1a18d52363eeb5014","value":0}},"5f75bdadc01249288e5ebaba35164918":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"648ba34c24a84a1b9f91be6448971824":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6791d40bbe834474860caae6ceaf81d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69754d6650c1403fb21b593af052ac65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bc990fc9b234c27bfb110a3d751b1b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6eb0aaedf965468b8e70a953517349bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"723a41d3a230445b9b6a5465b8142d4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfa3bff1628d4d2db11923c138d098ca","max":398,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33d5187ebde84f4ba9a1210c9f143a29","value":398}},"753e7fbec93344cba14268d1a344d9b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d871931d730540b28eb00eae798057ba","placeholder":"​","style":"IPY_MODEL_f8e142d4fbb04bb0912f652b0fd39915","value":"Loading checkpoint shards: 100%"}},"7691eea5acb64ab1a18d52363eeb5014":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"774bb2ba9ea74153a8e50ef9305568f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77cfeb2957f0472190457b94d201417d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7fcd83628d564dc1a53d7a00eb3704be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b39a6aca1e1d48128ed9404171acec81","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b44d7faecde94666b88a456d94e37222","value":3}},"80184e18ffba49e1b0d346075f8847db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35ec0363485c45138cd5ad2b2b01577e","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6bc990fc9b234c27bfb110a3d751b1b0","value":3}},"808e29b154da42f5941fe6394b943f6c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8094f165d19748dd991f3a65d0524ad9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"815aa4eff01e4ca79f71b1d4ec8f118c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_358147bc1d4649d483b1b79def664a91","placeholder":"​","style":"IPY_MODEL_8e6058898f6d44a287160985656fc1ea","value":"Download complete: "}},"8459e14d7863446ea785833668d70d74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_815aa4eff01e4ca79f71b1d4ec8f118c","IPY_MODEL_4315a87fc4fe43ee8e8b82aee857a32e","IPY_MODEL_99d25fb07d054a4aa2957ad542814a24"],"layout":"IPY_MODEL_215ec97ecaed4f5997321ac0d60c942e"}},"880855abf500493eb045c584d1c0e91c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39bc4c5bf9154269811a3c36be96413d","placeholder":"​","style":"IPY_MODEL_e866ed41010f46fa9f7073554ea4dbcb","value":"Loading weights: 100%"}},"8878971d51fe4a14af962a0ad8b23dcb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8979b08fdcf1475da563ad5db054b30f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89ecb0e3c4414cf98a3a5b1edf1d432b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e6058898f6d44a287160985656fc1ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"903946684afd49b7a25c9d45e403d115":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_880855abf500493eb045c584d1c0e91c","IPY_MODEL_723a41d3a230445b9b6a5465b8142d4e","IPY_MODEL_028e0fd6c450425d822215bc2414a006"],"layout":"IPY_MODEL_774bb2ba9ea74153a8e50ef9305568f5"}},"9512bc53ca5c40b1b046ca199b79be04":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"99d25fb07d054a4aa2957ad542814a24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8094f165d19748dd991f3a65d0524ad9","placeholder":"​","style":"IPY_MODEL_af63e6c73a194cfdbe1242e0ac8d98c7","value":" 0.00/0.00 [00:00&lt;?, ?B/s]"}},"9b2c7f48c41a4445958507b194f8108c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b770e603e3d47b28916edc63ca07399":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_feebbd458cff433791ec9a3e40759766","placeholder":"​","style":"IPY_MODEL_aa70ebb28905459ab0798a12d3126a6e","value":" 3/3 [00:02&lt;00:00,  1.45it/s]"}},"9b83966e037d4ae2ad5aee546e1647cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b9af38288514b4da376fcc29301f415":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7099744408a4facacee12597632f1bf","placeholder":"​","style":"IPY_MODEL_cfde084639e44898971dc5c75418ded6","value":"Fetching 3 files: 100%"}},"9ee1d63703c9432e97eac84be67e8adc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b43776cbcafa40c09f5651f9732a9797","placeholder":"​","style":"IPY_MODEL_56206a5dc9c04615915e8a2838885df3","value":" 531/3000 [1:06:47&lt;5:13:50,  7.63s/it, ftd=0.2691, rec=0.0408, tot=0.3100]"}},"9fd35afcfcb04d0ea3cada7f5c805179":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7a17cb16a904b0ba2da296af6a32848","max":3000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d52637d39cf245c7bd3203ebbed1b9cc","value":531}},"a3d0235a6b46485aa4c84240463747db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7099744408a4facacee12597632f1bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8e2a328c45f496c926d3ee58f3ef1fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa70ebb28905459ab0798a12d3126a6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac9b86aaca184d2bad828291532fd133":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af63e6c73a194cfdbe1242e0ac8d98c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2429185bc07459dafa0b6d00927b926":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b39a6aca1e1d48128ed9404171acec81":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b43776cbcafa40c09f5651f9732a9797":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b44d7faecde94666b88a456d94e37222":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7d6492475334a89ab16019078930e05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_808e29b154da42f5941fe6394b943f6c","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4535e2eb4a8a4593ba9479f8f22c1671","value":3}},"b97c4215c6e84cb69bcfef235008d1f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfa3bff1628d4d2db11923c138d098ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c14a4b70eb854a38ba9eb7a1a05dd9ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b9af38288514b4da376fcc29301f415","IPY_MODEL_574779dc772d4237860af2e68083a4b1","IPY_MODEL_1ccbf3bc21f64ff48da8f2caca19cec2"],"layout":"IPY_MODEL_e9968d88b2824a12b71afbda4ee72c7c"}},"c7a17cb16a904b0ba2da296af6a32848":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c80dac039a3b4bd684e5e25410b6d7e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9c2aaa925834f989653b862d2b34bf8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca04e651c49d44cd9bb6bdd891bf3931":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cef15156bb9941c397a645cfde47b003":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_648ba34c24a84a1b9f91be6448971824","placeholder":"​","style":"IPY_MODEL_0f0b5126a92943aaaf2731aeb51114c3","value":" 0.00/0.00 [00:00&lt;?, ?B/s]"}},"cfde084639e44898971dc5c75418ded6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d03a15f4ea904f20b30a50de351dfb24":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0e76ec973ca48228e2b68d2d60a8dfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01aa714afc164571831c174680e38093","IPY_MODEL_7fcd83628d564dc1a53d7a00eb3704be","IPY_MODEL_370bb61be8904c7a83acd65bea07e6a7"],"layout":"IPY_MODEL_6eb0aaedf965468b8e70a953517349bc"}},"d35144db20a64bc99be44bdbda676928":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d52637d39cf245c7bd3203ebbed1b9cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d79b1a48a8fc4820be0759cb9c339446":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4862f341caad4d1081ec189844be9719","placeholder":"​","style":"IPY_MODEL_52628cf128b744e28d6dfd2774f489c5","value":"Loading checkpoint shards: 100%"}},"d871931d730540b28eb00eae798057ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e309922ffab04880a1bb4f36200fc0a8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e567e8cc52b6496e8ed36779c7520ffc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e866ed41010f46fa9f7073554ea4dbcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9968d88b2824a12b71afbda4ee72c7c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea21b2b1dad2492480d772f1c621052e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24f14c413fff4dbf8363ecc30a89f4bd","placeholder":"​","style":"IPY_MODEL_3421381aa6844b1ebc534b0fd3b6a1b9","value":"FluxSR-FTD:  18%"}},"ed9030952f174480a2879599615144be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee68a451858545db919f8871c4979275":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d79b1a48a8fc4820be0759cb9c339446","IPY_MODEL_45cfeb2c23924d00a8e67912f675014f","IPY_MODEL_9b770e603e3d47b28916edc63ca07399"],"layout":"IPY_MODEL_89ecb0e3c4414cf98a3a5b1edf1d432b"}},"f61b1f37c02a4d82a62d9a8d63aa9e56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8e142d4fbb04bb0912f652b0fd39915":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"feebbd458cff433791ec9a3e40759766":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}